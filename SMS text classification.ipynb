{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout, LSTM, Bidirectional"
      ],
      "metadata": {
        "id": "K8Kv95LhSUae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_data = pd.read_csv(\"train-data.tsv\",sep='\\t', header= None)\n",
        "train_data.columns =['label', 'message']\n",
        "test_data = pd.read_csv(\"valid-data.tsv\",sep='\\t', header= None)\n",
        "test_data.columns =['label', 'message']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "train_data.groupby('label').describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "# get all the ham and spam emails\n",
        "ham_msg = train_data[train_data.label =='ham']\n",
        "spam_msg = train_data[train_data.label=='spam']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one of the ways to fix the data imbalance is to downsample the ham messages\n",
        "ham_msg_df = ham_msg.sample(n = len(spam_msg), random_state = 44)\n",
        "spam_msg_df = spam_msg\n",
        "print(ham_msg_df.shape, spam_msg_df.shape)"
      ],
      "metadata": {
        "id": "K2pmMT7Ic9MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with ham and spam messages\n",
        "train_msg = ham_msg_df.append(spam_msg_df).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "NbUBHuaOeDO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get length column for each text\n",
        "train_msg['text_length'] = train_msg['message'].apply(len)\n",
        "# calculate average length by label types\n",
        "labels = train_msg.groupby('label').mean()\n",
        "labels"
      ],
      "metadata": {
        "id": "DUIWZJHIdd_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map ham label as 0 and spam as 1\n",
        "train_msg['msg_type']= train_msg['label'].map({'ham': 0, 'spam': 1})\n",
        "test_data['msg_type']= test_data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "train_messages = train_msg['message']\n",
        "train_answers = train_msg['msg_type']\n",
        "test_messages = test_data['message']\n",
        "test_answers = test_data['msg_type']"
      ],
      "metadata": {
        "id": "L54R5k98ejj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining pre-processing hyperparameters\n",
        "max_len = 50\n",
        "trunc_type = \"post\"\n",
        "padding_type = \"post\"\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_size = 500"
      ],
      "metadata": {
        "id": "86hqG8W3fsNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use Tokenizer() to tokenize the words\n",
        "tokenizer = Tokenizer(num_words = vocab_size, char_level=False, oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(train_messages)\n",
        "\n",
        "# get the word_index\n",
        "word_index = tokenizer.word_index\n",
        "word_index"
      ],
      "metadata": {
        "id": "h5H25UVKfurr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many words\n",
        "tot_words = len(word_index)\n",
        "print('There are %s unique tokens in training data. ' % tot_words)"
      ],
      "metadata": {
        "id": "C8fmQABrk3p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sequencing and padding on training and testing\n",
        "training_sequences = tokenizer.texts_to_sequences(train_messages)\n",
        "training_padded = pad_sequences (training_sequences, maxlen = max_len, padding = padding_type, truncating = trunc_type )\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_messages)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen = max_len,\n",
        "padding = padding_type, truncating = trunc_type)"
      ],
      "metadata": {
        "id": "vyUQxV8zlEex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of train tensor\n",
        "print('Shape of training tensor: ', training_padded.shape)\n",
        "print('Shape of testing tensor: ', testing_padded.shape)"
      ],
      "metadata": {
        "id": "D_HQuDN8lQo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeding_dim = 16\n",
        "drop_value = 0.2 # dropout\n",
        "n_dense = 24\n",
        "\n",
        "# dense model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embeding_dim, input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dropout(drop_value))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "RCqCn-iJlWeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2bqU9VnSl9fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting a dense spam detector model\n",
        "num_epochs = 32\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(training_padded, train_answers, epochs=num_epochs, validation_data=(testing_padded, test_answers),callbacks =[early_stop], verbose=2)"
      ],
      "metadata": {
        "id": "mCBBVVfJmDu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model performance on test data\n",
        "model.evaluate(testing_padded, test_answers)"
      ],
      "metadata": {
        "id": "phpD61F0dA1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe\n",
        "metrics = pd.DataFrame(history.history)\n",
        "# rename column\n",
        "metrics.rename(columns = {'loss': 'Training_Loss', 'accuracy': 'Training_Accuracy',\n",
        "                         'val_loss': 'Validation_Loss', 'val_accuracy': 'Validation_Accuracy'}, inplace = True)\n",
        "def plot_graphs(var1, var2, string):\n",
        "    metrics[[var1, var2]].plot()\n",
        "    plt.title('Dense Classifier: Training and Validation ' + string)\n",
        "    plt.xlabel ('Number of epochs')\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([var1, var2])\n",
        "plot_graphs('Training_Loss', 'Validation_Loss', 'Loss')\n",
        "plot_graphs('Training_Accuracy', 'Validation_Accuracy', 'Accuracy')"
      ],
      "metadata": {
        "id": "f82tHtiMmYpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "def predict_message(text):\n",
        "  pred_text = []\n",
        "  pred_text.append(text)\n",
        "  new_seq = tokenizer.texts_to_sequences(pred_text)\n",
        "  padded = pad_sequences(new_seq, maxlen = max_len, padding = padding_type, truncating = trunc_type)\n",
        "  prediction = model.predict(padded)\n",
        "  result = []\n",
        "  for i in prediction:\n",
        "    if i > 0.5:\n",
        "      return (i.item(), 'spam')\n",
        "    else:\n",
        "      return (i.item(), 'ham')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today only! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {},
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}